---
title: "14. GAMLSS - zastosowania"
author: "Michał Maj"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: united
    number_sections: true
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.path="imgs/")
library(tidyverse)
library(ggeffects)
library(gamlss)
library(lme4)
```

# Uogólnione modele addytywne z parametrami położenia skali i kształtu - GAMLSS

## Model liniowy z heteroskedastycznością

Na poprzenich zajęciach rozważaliśmy model liniowy modelujący zależność miedzy wiekiem pacjenta, a ciśnieniem rozkurczowym:

$$
DIA|AGE \sim N(\mu, \sigma^2)\\
\mu = \beta_0 + \beta_1 AGE
$$

gdzie $DIA$ oznacza ciśnienie rozkurczowe, a $AGE$ oznacza wiek pacjenta.

```{r, message=FALSE, warning=FALSE}
blood <- read_csv2("blood.csv")
ggplot(blood, aes(age, diast)) + theme_bw() + geom_point() +
  xlab("WIEK") + ylab("CIŚNIENIE ROZKURCZOWE") +
  stat_smooth(method = "lm", se = TRUE)
```

W modelu tym występuje **heteroskedastyczność**, czyli niestałość wariancji. Oznacza to, że zalożenia powyższego modelu nie są spełnione. Jako alternatywę rozpatrzmy model:

$$
DIA|AGE \sim N(\mu, \sigma^2)\\
\mu = \beta_{01} + \beta_{11} AGE\\
\sigma = \beta_{02} + \beta_{12} AGE
$$

Poza wartością oczekiwaną chcemy także zamodelować odchylenie standardowe w naszym modelu, czyli mamy tu do czynienia z modelem rodziny $GAMLSS$. Podstawową funkcją w pakiecie `gamlss` jest funkcja `gamlss`, która odpowiada za tworzenie i dopasowanie modelu statystycznego. Aby do naszego modelu dodać równanie modelujące odchylenie standardowe musimy użyć argumentu `sigma.formula`. Porównajmy klasyczny model liniowy z modelem ze zmienną wariancją:

```{r}
blood_lm <- gamlss(formula = diast ~ age, data = blood, family = NO(sigma.link = "identity"))
blood_lm_het <- gamlss(formula = diast ~ age, sigma.formula = ~ age, data = blood, family = NO(sigma.link = "identity"))
```

Podsumowanie modelu liniowego daje nam te same wyniki co funkcja `lm`:

```{r}
summary(blood_lm)
blood <- blood %>%
  mutate(
    model_lm_pred = fitted(blood_lm, "mu"),
    model_lm_pred_sigma = fitted(blood_lm, "sigma")
  )
ggplot(blood, aes(x = age, y = diast)) + geom_point() + theme_bw() +
  geom_line(aes(y = model_lm_pred), color = "blue") +
  geom_line(aes(y = model_lm_pred + model_lm_pred_sigma), color = "red") +
  geom_line(aes(y = model_lm_pred - model_lm_pred_sigma), color = "red")
```

Sprawdźmy teraz jak wygląda model z heteroskedastycznością:

```{r}
summary(blood_lm_het)
blood <- blood %>%
  mutate(
    model_lm_het_pred = fitted(blood_lm_het, "mu"),
    model_lm_het_pred_sigma = fitted(blood_lm_het, "sigma")
  )
ggplot(blood, aes(x = age, y = diast)) + geom_point() + theme_bw() +
  geom_line(aes(y = model_lm_het_pred), color = "blue") +
  geom_line(aes(y = model_lm_het_pred + model_lm_het_pred_sigma), color = "red") +
  geom_line(aes(y = model_lm_het_pred - model_lm_het_pred_sigma), color = "red")
```

Porównanie modeli mozemy przeprowadzić a pomocą np. krytermium AIC lub R-squared:

```{r}
Rsq(blood_lm)
Rsq(blood_lm_het)
AIC(blood_lm, blood_lm_het)
```

## Od modelu liniowego do modelu GAMLSS

Rozpatrzmy teraz trochę bardziej skomplikowane dane. Zbiór danych `rent` zawiera obserwacje zebrane podczas badania przeprowadzonego w kwietniu 1993 r. Przez Infratest Sozialforschung. Wybrano losową próbę lokali z nowymi umowami najmu lub podwyżkami czynszu w ciągu ostatnich czterech lat w Monachium, obejmującą: i) pokoje jednoosobowe, ii) małe mieszkania, iii) mieszkania, iv) domy dwurodzinne. Mieszkania podlegające regulacjom cenowym, domy jednorodzinne i domy specjalne, takie jak penthouse'y, zostały wykluczone, ponieważ różnią się one raczej od reszty i są uważane za odrębny rynek. Na potrzeby niniejszego badania wykorzystano obserwacje z 1967 r. Zmiennych wymienionych poniżej, tj. Zmiennej odpowiedzi renty R, po której następują zmienne objaśniające.

Do modelowania uzyjemy następujących zmiennych:

- R - miesięczny czynsz pomniejszony o obliczone lub szacowane koszty mediów
- Fl - powierzchnia w $m^2$
- A - rok budowy
- H - dwupoziomowy współczynnik wskazujący, czy istnieje centralne ogrzewanie (0 - tak, 1 - nie)
- loc - czynnik wskazujący, czy lokalizacja jest poniżej średniej (1), średnia (2) lub powyżej średniej (3)

Zacznijmy od zbadania rozkładów zmiennych:

```{r}
data("rent")
ggplot(rent, aes(x = Fl, y = R)) + geom_point() + theme_bw()
ggplot(rent, aes(x = A, y = R)) + geom_point() + theme_bw()
ggplot(rent, aes(x = H, y = R)) + geom_boxplot() + theme_bw()
ggplot(rent, aes(x = loc, y = R)) + geom_boxplot() + theme_bw()
```

Pierwszy wykres ukazyjący wozkład czynszu względem pola powierzchni mieszkania sugeruje relację rosnącą (dodatnia korelacja), ze zwiększoną wariancją dla dużych powierzchni mieszkaniowych (czyli brak stałości wariancji). Istnieją również pewne oznaki (do przetestowania) prawostronnej skośności rozkładu czynszu.

Specyfika rozkładu czynszu na tle roku budowy, wynika z metody zbierania danych. Wiele obserwacji roku budowy zebrane zostało w skali interwałowej, a nastepnie uśrednione do srodka danego przedziału. Wykres ten sugeruje, że w przypadku mieszkań do 1960 r. średni czynsz jest mniej więcej stały, ale w przypadku mieszkań wybudowanych po tym roku mediana czynszu rośnie.

Dwa wykresy pudełkowe pokazują, jak zmienia się czynsz w zależności od zmiennych kategorycznych. Mediana czynszu rośnie, jeśli mieszkanie jest wyposażone w centralne ogrzewanie, a także wraz ze zmianą lokalizacji (poniżej średniej do średniej, a następnie powyżej średniej). Nie ma tu niespodzianek w, ale znowu problem skośności jest wyraźny, z asymetrycznymi pudełkami od mediany i dłuższym górnym niż dolnym wąsie.

Podsumowując, model statystyczny powinien sobie radzić z problemami:

1. Złożoność relacji między predyktorami a zmienną objaśnianą - najprawdopodobniej jest nieliniowa.
2. Niestałość wariancji zmiennej objaśnianej.
3. Skośność w rozkładzie zmiennej objaśnianej.

Póki co zaczniemy od modelu standardowej regresji liniowej i będziemy go rozwijać:

```{r}
r1 <- gamlss(formula = R ~ Fl + A + H + loc, family = NO, data = rent, trace = FALSE)
```

Dopsaowany model wygląda nastepująco:

$$
\hat{\mu}=-2775.04 + 8.84 Fl + 1.48 A -204.76(H=1)+134.05(loc=2)+ 209.58(loc=3) \\ \\
\log (\hat{\sigma})= 5.73165
$$

Zauważmy, że $\sigma$ modelowane jest przy użyciu logarytmicznej **funkcji łączącej**. Sprawdźmy dopasowanie naszego modelu:

```{r}
Rsq(r1)
plot(r1)
```

Założenia o normalności modelu można łatwo odrzucic patrząc na **Q-Q plot** (widać odejście od zależności liniowej między uporządkowanymi zaobserwowanymi znormalizowaymi kwantylami reszt i ich przybliżonymi wartościami oczekiwanymi), co sugeruje pozytywną skośność rozkładu. 

Dodatkowo wykres nr 1. (reszty vs wartości dopasowane) nie jest jednostajnie rozrzucowny wokół $0$ co może sugerować heteroskedastyczność.

Zauważmy dodatkowo, ze czynasz może przyjmować tylko i wyłącznie wartości dodatkie, co oznacza, że powinniśmy dostosować nasz rozkład.

Zmienimy więc nasz model z regresji liniowej na GLM z rozkładem Gamma.

$$
R|X \sim Gamma(\mu, \sigma^2)\\
log(\mu) = \beta_1 X\\
log(\sigma) = \beta_2
$$

w `gamlss` rozkład gamma ma następujacą parametryzację dla $\sigma$:

$$
\sigma=\sqrt{\phi}
$$

gdzie $\phi$ jest **paraetrem dyspersji**.

```{r}
r2 <- gamlss(formula = R ~ Fl + A + H + loc, family = GA, data = rent, trace = FALSE)
summary(r2)
```

Dopsaowany model wygląda nastepująco:

$$
\log (\hat{\mu})= 2.865 + 0.0106 Fl + 0.00151 A -0.3(H=1)+0.191(loc=2)+ 0.264(loc=3) \\ \\
\log(\hat{\sigma})= -0.9822
$$

Kolejnym pasującym rozkładem moze być **Inverse-Gamma**.

```{r}
r22 <- gamlss(formula = R ~ Fl + A + H + loc, family = IG, data = rent, trace = FALSE)
```

Wszystkie 3 modele mają tą samą liczbę parametrów dlatego możemy je porównać uogólnionym kryterium AIC:

```{r}
GAIC(r1, r2, r22, k = 0)
```

Wyglada na to, że rozkład Gamma daje najlepsze dopasowanie. Zobaczmy teraz wykresy dopasowania modelu:

```{r}
plot(r2)
```

Problemy, które mieliśmy do tej pory zostały częściowo rozwiązane, jednakże mozemty teraz wprowadzić nieliniowość do anszego modelu i zobaczyć czy poprawi to wyniki.

```{r}
r3 <- gamlss(R ~ pb(Fl) + pb(A) + H + loc, family = GA, data = rent, trace = FALSE)
AIC(r2, r3)
summary(r3)
```

Wygląda na to, że GAM z **P-splajnami** jest nieco lepszy niż GLM, jednakże powinniśmy wykonać dokładniszy test dla estymatorów nieliniowych. Możemy to zrobić przy pomocy funkcji `drop1`:

```{r}
drop1(r3)
```

Jak widać wszystkie zmienne są istotne. Możemy także zwizualizować dopasowanie zmiennych naszego modelu:

```{r}
term.plot(r3, pages = 1, ask = FALSE)
```

Widać, że wielkość czynszu zmienia się praktycznie liniowo względem pola powierzchni, a bardzo nieliniowo względem roku budowy. Dopasowanie modelu GAM możemy sprawdzić używająć **Worm plot** (QQ-plot dla reszt pozbawionych trendu):

```{r}
wp(r3, ylim.all = .6)
```

W kolejnym kroku do modelu GAM dodamy modelowanie odchylenia standardowego:

```{r}
r4 <- gamlss(R ~ pb(Fl) + pb(A) + H + loc, sigma.fo = ~ pb(Fl) + pb(A) + H + loc, family = GA, data = rent, trace = FALSE)
r5 <- gamlss(R ~ pb(Fl) + pb(A) + H + loc, sigma.fo = ~ pb(Fl) + pb(A) + H + loc, family = IG, data = rent, trace = FALSE)
AIC(r3, r4, r5)
```

Ponownie najlepszy okazuje się model z rozkładem Gamma. Sprawdźmy jak wygląda dopasowanie predyktorów i ich istotność dla odchylenia standardowego:

```{r}
term.plot(r4, pages = 1, what = "sigma", ask = FALSE)
drop1(r4, what = "sigma")
```

Jak widzimy centralne ogrzewanie nie ma wpływu na odchylenie standardowe.

```{r}
wp(r4, ylim.all = .6)
```

Kolejnym krokiem będzie zamodelowanie skośności. Musimy jednak odejść od rozkładu Gamma i wybrać jakiś gdzie skośność można zamodelować. Użyjemy rozkładu **BCCGo** (Box-Cox Cole and Green orig).

```{r}
r6 <- gamlss(R ~ pb(Fl) + pb(A) + H +  loc,
             sigma.fo = ~ pb(Fl) + pb(A) + H + loc,
             nu.fo = ~ 1,
             family = BCCGo, data = rent , trace = FALSE)
r7 <- gamlss(R ~ pb(Fl) + pb(A) + H +  loc,
             sigma.fo = ~ pb(Fl) + pb(A) + H + loc,
             nu.fo = ~ pb(Fl) + pb(A) + H + loc,
             family = BCCGo , data = rent , trace = FALSE)
AIC(r4, r6, r7)
```

Kryterium AIC mówi, że dopasowanie rozkładem BCCgo jest lepszym rozwiązaniem niz rozkład Gamma:

```{r}
wp(r6, ylim.all = .6); title("r6: BCCG(mu, sigma)")
wp(r7, ylim.all = .6); title("r7: BCCG(mu, sigma, nu)")
```

Oba modele dają dobre dopasowanie, wiec możemy zakonczyć analizę.

## Modele mieszane

Za początek rozpatrzmy prosty przykład. Wyobraźmy sobie, że badamy zależność między ciśnieniem krwi, a paleniem papierosów. Zebraliśmy w każdej grupie $10$ pacjentów i od kazdego z nich pobraliśmy $5$ pomiarów w ciągu najbliższych 24 godzin. W klasycznym przypadku stworzylibyśmy nasz prosty model liniowy (t-test, ANOVA) gdzie predyktorem byłbaby zmienna mówiąca o tym czy dany pacjent pali czy nie, a zmienną objaśnianą byłoby ciśnienie. Zauważmy jednak, że eksperyment stworzony w ten sposób wprowadza dodatkową zmienną, a mianowicie ID pacjenta. Zauważmy, że kazde 5 próbek od danego pacjenta może być ze sobą skorelowane i każdy pacjent moze miec inny wyjściowy poziom ciśnienia. Informację tę należałoby uwzględnić w naszym modelu, jednakże nie interesuje nas dokładny wpływ każdego pacjenta (nie chcemy dodatkowej $\beta$ dla każdego pacjenta) jak to było w przypadku zmiennej mówiącej o paleniu. Zmianne mówiąca o paleniu jest w tym przypadku **efektem stałym** (fixed effect), a ID pacjenta jest **efektem losowym** (random efect). Model z obiema typami efektów nazwiemy **modelem mieszanym** (mixed model). Klasycznym rozszerzeniem GLM są GLMM czyli **Uogólnione mieszane modele liniowe**:

$$
\left\{\begin{array}{l}
y|X \sim O E F(\mu(\theta), \phi) \\
g(\mu)=\eta=X \beta + Zu\\
u \sim N(0, G)
\end{array}\right.
$$

Zmienna, która traktowana jest jako efekt stały w jednym modelu, traktowana może być jako efekt losowy w innym, dlatego też nalezy zastanowić się nad konstrukcją modelu w zalezności od tego jak skonstruowany był eksperyment i to na jakie pytanie chcemy odpowiedzieć. O efektach losowych możemy mysleć jak o efektach dla konkretnych podgrup, z większej możliwej liczby grup z całej populacji (mamy kilku pacjentów z większej ilości), gdzie efekty te nie są istotne do określenia w naszej analize.

Zacznijmy od prostego fikcyjnego przykładu. Interesować nas będzie zaleźność między zmienną `testScore` mówiącej o inteligencji, a predyktorem `bodyLength` mówiącej o rozmiarze smoka:

```{r}
load("dragons.RData")
dragons$X <- NULL
dragons$bodyLength2 <- scale(dragons$bodyLength, center = TRUE, scale = TRUE)
ggplot(dragons, aes(x = testScore)) + theme_bw() + geom_histogram(bins = 30)
```

Klasycznym podejściem byłoby zaczęcie od modelu regresji liniowej:

```{r}
basic.lm <- gamlss(formula = testScore ~ bodyLength2, data = dragons)
summary(basic.lm)
ggplot(dragons, aes(x = bodyLength2, y = testScore)) +
  theme_bw() +
  geom_point() +
  geom_smooth(method = "lm")
```

Wydaje się, że inteligencja rośnie wraz z rozmiarem co jest nieco nieoczekiwane. Sprawdźmy więc dopasowanie naszego modelu:

```{r}
plot(basic.lm)
```

Zauważmy, że pomineliśmy zmienną `mountainRange` mówiacą o tym gdzie została zebrana obserwacja:

```{r}
ggplot(dragons, aes(x = mountainRange, y = testScore)) + theme_bw() + geom_boxplot()
ggplot(dragons, aes(x = bodyLength, y = testScore, color = mountainRange)) +
  theme_bw() +
  geom_point()
```

Powyższe wykresy pokazują, że zebrane obserwacje nie są niezależne dla kokretnych grup `mountainRange`. Pokazuje to, że powinniśmy uwzględnić tę zmienną w modelu, dodajmy ja wiec do naszego równania:

```{r}
ggplot(aes(bodyLength, testScore), data = dragons) +
  geom_point() +
  theme_bw() +
  facet_wrap(~ mountainRange) +
  xlab("length") + 
  ylab("test score")
mountain.lm <- gamlss(formula = testScore ~ bodyLength2 + mountainRange, data = dragons)
summary(mountain.lm)
```

Zauważmy, że po dodaniu zmiennej `mountainRange` zmienna `bodyLength2` stała się nieistotna. Pomyślmy przez chwilę o tym, co tutaj robimy. Powyższy model szacuje **różnicę w wynikach testów między pasmami górskimi**. Ale nie jesteśmy zainteresowani ilościowym określaniem wyników testów dla każdego konkretnego pasma górskiego: chcemy tylko wiedzieć, czy **długość ciała wpływa na wyniki testów** i chcemy po prostu **kontrolować zmienność pochodzącą z pasm górskich**. Powinniśmy więc użyćmodelu mieszanego z pasmem górskim jako efektem losowym. dopiero takie rozwiązanie pozwoli nam na uwzględnienie korelacji między obserwacjami w danej grupie (paśmie górskim), zmniejszymy liczbę parametrów naszego modelu i pozbędziemy się problemu **wielokrotnym porównań** (multiple comparisons).

```{r}
mixed.lmer <- lmer(testScore ~ bodyLength2 + (1|mountainRange), data = dragons)
summary(mixed.lmer)
```

```{r}
mixed.lmer2 <- gamlss(formula = testScore ~ bodyLength2 + re(random = ~1|mountainRange), data = dragons)
summary(mixed.lmer2)
```

Sprawdźmy dopasowanie nowego modelu:

```{r}
plot(mixed.lmer2)
```

Efekty losowe mogą być:

- **krzyżowe** (crossed):

Pomyśl na przykład o naszym badaniu, w którym monitorujesz smoki (obiekt) w różnych pasmach górskich (kontekst) i wyobraź sobie, że zbieramy wiele obserwacji każdego smoka, wykonując test wiele razy. Ponieważ nasze smoki potrafią latać, łatwo sobie wyobrazić, że możemy obserwować tego samego smoka w różnych pasmach górskich, ale także, że możemy nie zobaczyć wszystkich smoków odwiedzających wszystkie pasma górskie. Dlatego możemy potencjalnie obserwować każdego smoka w każdym łańcuchu górskim (krzyżowe) lub przynajmniej obserwować niektóre smoki w niektórych pasmach górskich (częściowo krzyżowe). Następnie dopasowalibyśmy tożsamość smoka i pasma górskiego jako (częściowo) skrzyżowane losowe efekty.

- **zagnieżdżone** (nested):

Często zdarza się, że w grupach, które traktujemy jak efekt losowy mogą pojawic się podgrupy (a w nich kolejne). mamy wtedy do czyniena z efektem zagniezdżonym. Przykładem może być badanie, w którym mamy pacjentów z wielu miast, w kazdym mieście, kilka szpitali i w każdym szpitalu pacjentów z grupy kontrolnej i przyjmującej leki. Dodatkowo mogliśmy zebrać kilka pomiarów od kazdego pacjenta.

Spójrzmy na kolejny aspekt naszego badania: zebraliśmy dane o smokach nie tylko w wielu pasmach górskich, ale także w kilku miejscach w tych pasmach górskich (zmienna `site`).

Nasza zmienna `site` jest czynnikiem trójpoziomowym, z poziomami nazywanymi `a`, `b` i `c`. Zagnieżdżenie obszaru w paśmie górskim jest domniemane - nasze stanowiska są bez znaczenia bez przypisania ich do określonych pasm górskich, tj. Nie ma nic, co łączy stanowisko `b` pasma górskiego `Bavarian` z obszarem `b` pasma górskiego `Central`. Aby uniknąć przyszłych nieporozumień, powinniśmy utworzyć nową zmienną, która jest jawnie zagnieżdżona:

```{r}
dragons <- within(dragons, sample <- factor(mountainRange:site))
```

```{r}
mixed.WRONG <- lmer(testScore ~ bodyLength2 + (1|mountainRange) + (1|site), data = dragons) # traktuje dwa efekty losowe jako krzyżowe
summary(mixed.WRONG)
```

```{r}
mixed.lmer3 <- lmer(testScore ~ bodyLength2 + (1|mountainRange) + (1|sample), data = dragons) # kod jest taki sam, jednakże zagniezdżenie zostaje uwzględnione
summary(mixed.lmer3)
```

Zwizualizujmy nowe wyniki:

```{r}
ggplot(dragons, aes(x = bodyLength, y = testScore, colour = site)) +
  facet_wrap(~ mountainRange, nrow = 2) +
  geom_point(alpha = 0.5) +
  theme_classic() +
  geom_line(data = cbind(dragons, pred = predict(mixed.lmer3)), aes(y = pred), size = 1) +
  theme(legend.position = "none",
        panel.spacing = unit(2, "lines"))
```

Jak łatwo zauważyć wszystkie krzywe regresji są do siebie równoległe. Dzieje się tak dlatego, że do tej pory dopasowaliśmy tylko modele **random-intercept**. Model ten pozwala na zmianę punktu przecięcia na każdym poziomie efektów losowych, ale utrzymuje między nimi stałe nachylenie. Tak więc w naszym przypadku użycie tego modelu oznacza, że spodziewamy się, że smoki we wszystkich pasmach górskich będą wykazywać ten sam związek między długością ciała a inteligencją (stałe nachylenie), chociaż przyznajemy, że niektóre populacje mogą być mądrzejsze lub głupsze.

W naukach przyrodniczych być może częściej zakładamy, że nie wszystkie populacje wykazywałyby dokładnie ten sam związek, na przykład, jeśli twoje populacje badawcze są bardzo daleko od siebie i mają pewne względnie ważne różnice środowiskowe, genetyczne itp. Dlatego często chcemy dopasować model **random-slope and random-intercept**. Być może smoki w bardzo zimnym i bardzo ciepłym paśmie górskim wyewoluowały różne formy ciała w celu zachowania ciepła i dlatego mogą być inteligentne, nawet jeśli są mniejsze niż przeciętne.

```{r}
mixed.ranslope <- lmer(testScore ~ bodyLength2 + (1 + bodyLength2|mountainRange/site), data = dragons) 
summary(mixed.ranslope)
```

Zwizualizujmy wyniki:

```{r}
ggplot(dragons, aes(x = bodyLength, y = testScore, colour = site)) +
  facet_wrap(~mountainRange, nrow = 2) +
  geom_point(alpha = 0.5) +
  theme_classic() +
  geom_line(data = cbind(dragons, pred = predict(mixed.ranslope)), aes(y = pred), size = 1) + 
  theme(legend.position = "none",
        panel.spacing = unit(2, "lines"))
```

## Mieszaniny rozkładów

Załózmy, ze zmienna losowa $Y$ pochodzi z komponentu $k$ z gęstością $f_k(y)$ z prawdopodobieństwem $\pi_k$, $k = 1,2,...,K$. Wtedy rozkład (marginalny) zmiennej $Y$ dany jest wzorem:

$$
f_Y(y) = \sum_{k=1}^K \pi_k f_k(y)
$$
gdzie $0\leq \pi_k \leq 1$ i $\sum \pi_k = 1$. W ogólnym przypadku gestość $f_k(y)$ może zalezeć od parametrów $\theta_k$ oraz zmiennych objasniających $X_k$:

$$
f_k(y) = f_k(y|\theta_k,X_k)
$$
Podobnie $f_Y(y)$ zależy od parametru $\psi = (\theta, \pi)$, gdzie $\theta = (\theta1, ..., \theta_K)$ i $\pi = (\pi_1, ..., \pi_K)$:

$$
f_{Y}(y \mid \psi, X)=\sum_{k=1}^{K} \psi_{k} f_{k}\left(y \mid \theta_{k}, X_{k}\right)
$$
Rozpatrzmy na początek prosty przykład **estymacji gęstości**. Potrzebny nam bedzie dodatkowy pakiet `gamlss.mx` umożliwiającey dopasowanie **mieszaniny rozkłądów**. Fukcja `gamlssMX` odpowiada za dopasowanie modelu. Arument `K` pozwala na zdefiniowanie ilości użytych rozkładów. 

```{r}
library(gamlss.mx)
library(MASS)
data(enzyme)

truehist(enzyme$act, h = 0.1)
m1 <- gamlssMX(act ~ 1, data = enzyme, family = NO, K = 2)
m2 <- gamlssMX(act ~ 1, data = enzyme, family = GA, K = 2)
m3 <- gamlssMX(act ~ 1, data = enzyme, family = RG, K = 2)
m4 <- gamlssMX(act ~ 1, data = enzyme, family = c(NO, GA), K = 2)
m5 <- gamlssMX(act ~ 1, data = enzyme, family = c(NO, RG), K = 2)
AIC(m1, m2, m3, m4, m5)
```

AIC mówi, że najlepszy model to mieszanina 2 rozkładów **Reverse Gumbel**. Algorytm E-M potrafi utknać w minimum lokalnym, awy wykluczyć taką mozliwość możemy powtórzyć proces kilka razy z różnym punktem startu:

```{r}
set.seed(1436)
m3 <- gamlssMXfits(n = 10, act ~ 1, data = enzyme, family = RG, K = 2)
```

Sprawdźmy teraz podsumowanie naszego modelu:

```{r}
m3

truehist(enzyme$act, h = 0.1)
fyRG <- dMX(y = seq(0, 3, 0.01), mu = list(1.127, 0.1557), sigma = list(exp(-1.091),
                                                                        exp(-2.641)), pi = list(0.376, 0.624), family = list("RG", "RG"))
lines(seq(0, 3, 0.01), fyRG, col = "red", lty = 1)
lines(density(enzyme$act, width = "SJ-dpi"), lty = 2)
```

Przejdźmy teraz do danych wielowymiarowych. Dane `geyser` zawierają informacje o czasie oczekiwania na erupcję oraz jej długość.

```{r}
data(geyser)
set.seed(1581)
mNO <- gamlssMX(waiting ~ 1, data = geyser, family = NO, K = 2)
mGA <- gamlssMX(waiting ~ 1, data = geyser, family = GA, K = 2)
mRG <- gamlssMX(waiting ~ 1, data = geyser, family = RG, K = 2)
mGU <- gamlssMX(waiting ~ 1, data = geyser, family = GU, K = 2)
mLO <- gamlssMX(waiting ~ 1, data = geyser, family = LO, K = 2)
mIG <- gamlssMX(waiting ~ 1, data = geyser, family = IG, K = 2)
AIC(mNO, mGA, mRG, mGU, mLO, mIG)
```

Najlepszy okazuje się być model z mieszaniną rozkładów Inverse Gamma:

```{r}
mIG

truehist(geyser$waiting, h = 2)
fyIG <- dMX(y = seq(39, 115, 1), mu = list(exp(4.393), exp(4.006)),
            sigma = list(exp(-4.642), exp(-4.304)),
            pi = list(0.6695835, 0.3304165),
            family = list("IG", "IG"))
lines(seq(39, 115, 1), fyIG, col = "red", lty = 1)
lines(density(geyser$waiting, width = "SJ-dpi"), lty = 2)
```

W kolejnym kroku sprawdzimy czy dopasowanie naszego modelu nie będzie lepsze jeśli jako predyktora nie uzyjemy czasu poprzeniej erupcji:

```{r}
geyser2 <- matrix(0, ncol = 2, nrow = 298)
geyser2[, 1] <- geyser$waiting[-1]
geyser2[, 2] <- geyser$duration[-299]
colnames(geyser2) <- c("waiting", "duration")
geyser2 <- data.frame(geyser2)
set.seed(1581)
mNO1 <- gamlssMX(waiting ~ 1, data = geyser2, family = NO, K = 2)
mIG1 <- gamlssMX(waiting ~ 1, data = geyser2, family = IG, K = 2)
mNO2 <- gamlssMX(waiting ~ 1, pi.formula = ~duration, data = geyser2, family = NO, K = 2)
mIG2 <- gamlssMX(waiting ~ 1, pi.formula = ~duration, data = geyser2, family = IG, K = 2)
mNO3 <- gamlssMX(waiting ~ duration, pi.formula = ~1, data = geyser2, family = NO, K = 2)
mIG3 <- gamlssMX(waiting ~ duration, pi.formula = ~1, data = geyser2, family = IG, K = 2)
mNO4 <- gamlssMX(waiting ~ duration, pi.formula = ~duration, data = geyser2, family = NO, K = 2)
mIG4 <- gamlssMX(waiting ~ duration, pi.formula = ~duration, data = geyser2, family = IG, K = 2)
AIC(mNO1, mNO2, mNO3, mNO4, mIG1, mIG2, mIG3, mIG4)
```

Sprawdźmy dopasowanie najlepszego modelu:

```{r}
mIG4

op <- par(mfrow = c(1, 2))
plot(waiting ~ duration, data = geyser2, xlab = "previous duration",
     ylab = "waiting time", main = "(a)")
lines(fitted(mIG4$models[[1]])[order(geyser2$duration)] ~
        geyser2$duration[order(geyser2$duration)],
      col = "dark green", lty = 3)
lines(fitted(mIG4$models[[2]])[order(geyser2$duration)] ~
        geyser2$duration[order(geyser2$duration)],
      col = "red", lty = 4)
plot(mIG4$prob[, 1][order(duration)] ~ duration[order(duration)],
     data = geyser2, xlab = "previous duration", ylab = "probability of component 2",
     main = "(b)")
lines(mIG4$prob[, 1][order(duration)] ~ duration[order(duration)],
      data = geyser2)
lines(mIG4$prob[, 1][order(duration)] ~ duration[order(duration)],
      data = geyser2)
par(op)
```

Zobaczmy także dopasowany rozkład w 3D

```{r}
grid <- expand.grid(duration = seq(1.5, 5.5, 0.1), waiting = seq(40,
                                                                 110, 0.5))
etapi <- 10.19069 - 3.132215 * grid$duration
etamu1 <- 4.09618 + 0.07007 * grid$duration
etamu2 <- 3.6312 + 0.1935 * grid$duration
pp <- (exp(etapi)/(1 + exp(etapi)))
grid$f1 <- dMX(y = grid$waiting, mu = list(exp(etamu1), exp(etamu2)),
               sigma = list(exp(-4.807), exp(-4.351)), pi = list(1 - pp, pp),
               family = list("IG", "IG"))
library(lattice)
wireframe(f1 ~ duration * waiting, data = grid, aspect = c(1,
                                                           0.5), drape = TRUE)
```

W kolejnym kroku moglibyśmy sprawdzić czy predyktor nieliniowy nie byłby lepszym rozwiazaniem:

```{r}
mIG5 <- gamlss(waiting ~ duration, sigma.formula = ~duration,
               data = geyser2, family = IG, trace = FALSE)
mIG6 <- gamlss(waiting ~ cs(duration), sigma.formula = ~duration,
               data = geyser2, family = IG, trace = FALSE)
mIG7 <- gamlss(waiting ~ cs(duration), sigma.formula = ~cs(duration),
               data = geyser2, family = IG, trace = FALSE)
mIG8 <- gamlss(waiting ~ cs(duration), sigma.formula = ~1, data = geyser2,
               family = IG, trace = FALSE)
AIC(mIG4, mIG5, mIG6, mIG7, mIG8)

plot(waiting ~ duration, data = geyser2, xlab = "previous duration",
     ylab = "waiting time")
lines(fitted(mIG4$models[[1]])[order(geyser2$duration)] ~
        geyser2$duration[order(geyser2$duration)],
      col = "green", lty = 3)
lines(fitted(mIG4$models[[2]])[order(geyser2$duration)] ~
        geyser2$duration[order(geyser2$duration)],
      col = "red", lty = 4)
lines(fitted(mIG6)[order(duration)] ~ duration[order(duration)],
      data = geyser2, col = "blue", lty = 1)
```


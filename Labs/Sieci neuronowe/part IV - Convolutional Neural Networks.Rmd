---
title: "part IV - Convolutional Neural Networks"
author: "Michał Maj"
output: html_notebook
---

```{r packages}
library(keras)
library(tidyverse)
library(grid)
library(gridExtra)
```

Zanim zbudujemy CNN w Keras, musimy zrozumieć konwolucję i pooling. Załaduj obraz „data/zebra.jpg”

```{r image_load}
zebra <- image_load("data/zebra.jpg", grayscale = TRUE, target_size = c(200, 300)) %>%
  image_to_array() %>% `/`(255)
image(t(zebra[, , 1])[, nrow(zebra):1], col = grey(seq(0, 1, length = 256)), axes = F)
```

Teraz możemy zaimplementować prostą konwolucję:

```{r 2d_convolution}
sobel_filter_x <- matrix(c(1, 2, 1, 0, 0, 0, -1, -2, -1), 3, 3, byrow = FALSE)

kernel_shape <- 3
padding <- 0
stride <- 1
input_height <- nrow(zebra)
input_width <- ncol(zebra)
activation_map_height <- (input_height + 2 * padding - kernel_shape) / stride + 1
activation_map_width <- (input_width + 2 * padding - kernel_shape) / stride + 1
activation_map <- matrix(0, nrow = activation_map_height, ncol = activation_map_width)

for (w in 1:ncol(activation_map)) {
  for (h in 1:nrow(activation_map)) {
    activation_map[h, w] <- sum(sobel_filter_x * zebra[h:(h + kernel_shape - 1), w:(w + kernel_shape - 1), 1])
  }
}

image(t(activation_map)[, nrow(activation_map):1], col = grey(seq(0, 1, length = 256)), axes = F)
```

oraz pooling:

```{r 2d_max_pooling}
pool_shape <- 2
pool_stride <- 2
activation_map2_height <- activation_map_height / pool_shape
activation_map2_width <- activation_map_width / pool_shape
activation_map2 <- matrix(0, nrow = activation_map2_height, ncol = activation_map2_width)

for (w in 1:ncol(activation_map2)) {
  for (h in 1:nrow(activation_map2)) {
    activation_map2[h, w] <- max(activation_map[(2 * (h - 1) + 1):((2 * (h - 1) + 1) + pool_shape - 1), (2 * (w - 1) + 1):((2 * (w - 1) + 1) + pool_shape - 1)])
  }
}

image(t(activation_map2)[, nrow(activation_map2):1], col = grey(seq(0, 1, length = 256)), axes = F)
```

Zaczniemy od zbudowania prostego CNN dla zbioru danych dotyczących mody. Na pierwszym spotkaniu stworzyliśmy MLP do tego zadania. Załadujmy zbiór danych:

```{r fashion_mnist}
load("data/fashion_mnist.RData")
xy_axis <- data.frame(x = expand.grid(1:28, 28:1)[, 1],
                      y = expand.grid(1:28, 28:1)[, 2])
plot_theme <- list(
  raster = geom_raster(hjust = 0, vjust = 0),
  gradient_fill = scale_fill_gradient(low = "white", high = "black", guide = "none"),
  theme = theme_void()
)

sample_plots <- sample(1:nrow(fashion_mnist_train_X), 100) %>% map(~ {
  plot_data <- cbind(xy_axis, fill = data.frame(fill = fashion_mnist_train_X[.x, ]))
  ggplot(plot_data, aes(x, y, fill = fill)) + plot_theme
})

do.call("grid.arrange", c(sample_plots, ncol = 10, nrow = 10))
```

Aby przesłać dane do modelu CNN w keras, musimy przekształcić nasze je w odpowiednie tensory. Podobnie jak w przypadku MLP musimy przekształcić wektor etykiet do macierzy z kodowaniem one-hot-encoding. W przypadku naszych obrazów musimy przedstawić je jako tensor 4-wymiarowy (próbki, wysokość, szerokość, kanały). Musimy również pamiętać o znormalizowaniu wartości pikseli:

```{r fashion_mnist_data}
fashion_mnist_train_Y <- fashion_mnist_train_Y %>% to_categorical(., 10)
fashion_mnist_test_Y <- fashion_mnist_test_Y %>% to_categorical(., 10)

fashion_mnist_train_X <- fashion_mnist_train_X / 255
fashion_mnist_test_X <- fashion_mnist_test_X / 255

fashion_mnist_train_X <- array_reshape(fashion_mnist_train_X, c(nrow(fashion_mnist_train_X), 28, 28, 1))
fashion_mnist_test_X <- array_reshape(fashion_mnist_test_X, c(nrow(fashion_mnist_test_X), 28, 28, 1))

dim(fashion_mnist_train_X)
```

Dane są w poprawnej formie tensorowej, możemy przystąpić do budowy modelu. Jak zawsze będzie to model sekwencyjny. Jako pierwszą warstwę użyjemy warstwy konwolucyjnej:

```{r fashion_mnist_conv_layer}
fmnist_model1 <- keras_model_sequential() %>%
  # 2D convolution, 32 filters of size 3x3, input c(28, 28, 1) - grayscale
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = 'relu',
                input_shape = c(28, 28, 1))
fmnist_model1
```

Dlaczego mamy do wytrenowania 320 parametrów?

```{r fashion_mnist_conv_layer_params}
32 * (3 * 3 * 1 + 1) # 32 filters of size 3x3(x1) + bias for each of them
```

Dlaczego output ma kształt (None, 26, 26, 32) ? 

```{r fashion_mnist_conv_layer_output_shape}
((28 - 3 + 2 * 0) / 1) + 1 # 28 - input image size, 3 - kernsl size, 0 - padding, 1 - stride
```

Po warstwie konwolucyjnej możemy dodać kolejną. Użyjmy warstwy max pooling:

```{r fashion_mnist_max_pool_layer}
fmnist_model1 %>%
  # 2D max pooling size 2x2(x1)
  layer_max_pooling_2d(pool_size = c(2, 2))
fmnist_model1
```

Dlaczego output ma kształt (None, 12, 12, 32) ?

```{r fashion_mnist_max_pool_layer_output_shape}
26 / 2 # 26 - input of the activation map shape, 2 - pool size
```

Powiedzmy, że chcemy dokończyć naszą architekturę i dodać warstwę wyjściową. zrobimy to w taki sam sposób jak w MLP, ale zanim to zrobimy, musimy spłaszczyć naszą ostatnią mapę aktywacji do wektora:

```{r fashion_mnist_output_layer}
fmnist_model1 %>%
  # Tensor flattening into vector form
  layer_flatten() %>%
  # Output layer - 10 classes, softmax activation
  layer_dense(units = 10, activation = 'softmax')

fmnist_model1
```

Dlaczego output ma kształt (None, 5408) ?

```{r fashion_mnist_flatten_layer_output_shape}
13 * 13 * 32 # Check dimmentions of previous layer
```

Dlaczego mamy 54090 parametrów do trenowania w warstwie wyjściowej?

```{r fashion_mnist_output_layer_output_shape}
5408 * 10 + 10 # 5408 - from layer_flatten * 10 neurons + biases
```

Architertura CNN jest ukończona, możemy teraz skompilować model:

```{r fashion_mnist_compile}
fmnist_model1 %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)
```

i go wytrenować:

```{r fashion_mnist_fit}
history <- fmnist_model1 %>% fit(
  fashion_mnist_train_X,
  fashion_mnist_train_Y,
  batch_size = 128,
  epochs = 30,
  validation_split = 0.2,
  callbacks = c(callback_model_checkpoint(monitor = "val_accuracy",
                                          filepath = "models/fmnist_model1.hdf5",
                                          save_best_only = TRUE))
) 
```

oraz zewaluować na zbiorze testowym:

```{r fashion_mnist_evaluate}
fmnist_model1 %>% evaluate(fashion_mnist_test_X, fashion_mnist_test_Y)
```

Czas na stworzenie bardziej zaawansowanej wersji tego modelu:

```{r fashion_mnist_ex}
# Ex. Expand model by adding batch normalization. Add early stopping and Tensorboard callbacks.
# 1. Model architecture:
# 2D convolution with 64 filters of size 3x3, 1x1 stride, 'linear' activation, "same" padding
# Batch normalization layer
# "relu" activation layer
# 2D max pooling size 2x2, 2x2 stride
# dropout layer with 25% drop rate
# Flattening layer
# dense layer with 512 neurons and "relu" activation
# dropout layer with 25% drop rate
# Choose correct layer as output

# 2. Compile model with Adadelta optimizer - set learning rate 0.01, decay = 1e-6.

# 3. Fit the model - beside standart settings add callbacks:
# model checkpoint - save model as "fmnist_model2.hdf5" in "models" folder
# early stopping - will stop training if there's no progress (monitor "val_accuracy" and don't wait more than 5 epochs)
# tensorboard - save logs to tensorboard in "tensorboard" folder - callback_tensorboard

# 4. Evaluate the model on test set
```

